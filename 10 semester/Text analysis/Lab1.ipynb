{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huXIElnBO1Cb",
        "outputId": "14f95273-26ad-48eb-c1af-ef5eacdaa57f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/drive/My Drive/NLP')"
      ],
      "metadata": {
        "id": "xwvkLhzDPhqb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v642FOVa9MFu",
        "outputId": "b79cbd56-cf72-49b5-c4a6-0e5d349b240d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_text(name_txt):\n",
        "  with open(name_txt, 'r') as file:\n",
        "    text = file.readlines()\n",
        "  return ' '.join(text)"
      ],
      "metadata": {
        "id": "DUCjhALM91HI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uk_text = ''.join(read_text('uk_text.txt')).lower()\n",
        "en_text = ''.join(read_text('en_text.txt')).lower()\n",
        "print(uk_text)\n",
        "print(en_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-AzQF1T-YO5",
        "outputId": "b62ea021-4f13-4c23-bda4-5a22b2abd347"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì∏ —Ö–æ—á—É –≤–∏–π—Ç–∏ –Ω–∞ —Ñ–æ—Ç–æ —è–∫ ...\n",
            " –Ω—ñ –≤ —è–∫–æ–º—É —Ä–∞–∑—ñ –Ω–µ –ø–æ—Ç—Ä—ñ–±–Ω–æ –ø–æ—Ä—ñ–≤–Ω—é–≤–∞—Ç–∏ —Å–µ–±–µ –∑ –∫–∏–º–æ—Å—å –∞–±–æ –∫–æ–≥–æ—Å—å –Ω–∞—Å–ª—ñ–¥—É–≤–∞—Ç–∏. –≤—Å—ñ –º–∏ —Ä—ñ–∑–Ω—ñ –≤—ñ–¥ –ø—Ä–∏—Ä–æ–¥–∏ —ñ —è–∫—â–æ –æ–¥–Ω–æ–º—É –æ–±—Ä–∞–∑ –π–¥–µ –Ω–∞ 100 –≤—ñ–¥—Å–æ—Ç–∫—ñ–≤, —Ç–æ —ñ–Ω—à–∏–π –≤ –Ω—å–æ–º—É –º–æ–∂–µ –ø–æ–±–∞—á–∏—Ç–∏ —Å–µ–±–µ –Ω–µ –∫—Ä–∞—Å–∏–≤–∏–º. —à—É–∫–∞—î–º–æ —Ç–æ —â–æ –π–¥–µ —Ç—ñ–ª—å–∫–∏ –≤–∞–º!\n",
            " üì∏–æ–±—Ä–∞–∑ –Ω–µ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î —Å—Ç–æ—Ä–æ–Ω–∏!\n",
            " —á–∞—Å—Ç–æ –≤–∏ –Ω–µ –ø–æ–¥–æ–±–∞—î—Ç–µ—Å—è —Å–æ–±—ñ –Ω–∞ —Ñ–æ—Ç–æ –Ω–µ —Ç–æ–º—É —â–æ –≤–∏ –ø–æ–≥–∞–Ω–æ –≤–∏–π—à–ª–∏ –≤ –∫–∞–¥—Ä—ñ, –∞ —Ç–æ–º—É —â–æ –ø—Ä–æ—Å—Ç–æ –≤–∞—à –æ–¥—è–≥ –∞–±—Å–æ–ª—é—Ç–Ω–æ –Ω–µ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î —Å—Ç–∏–ª—é –æ–±—Ä–∞–Ω–æ—ó –ª–æ–∫–∞—Ü—ñ—ó. –∑–∞–≤–∂–¥–∏ –æ–±–≥–æ–≤–æ—Ä—é–π—Ç–µ —Ü–µ–π –º–æ–º–µ–Ω—Ç –∑ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–æ–º, –≤–æ–Ω–∞ / –≤—ñ–Ω –∑–∞–≤–∂–¥–∏ –∑ —Ä–∞–¥—ñ—Å—Ç—é –≤–∞–º —â–æ—Å—å –ø—ñ–¥–∫–∞–∂–µ —ñ –ø—ñ–¥–±–µ—Ä–µ –æ–¥—è–≥ –¥–æ —Ñ–æ—Ç–æ—Å—Ç—É–¥—ñ—ó.\n",
            " —Ä–µ—Ç–µ–ª—å–Ω–æ –ø—ñ–¥–±–∏—Ä–∞–π—Ç–µ –æ–±—Ä–∞–∑–∏ –Ω–∞ —Ñ–æ—Ç–æ—Å–µ—Å—ñ—é, –º–∞–∫—ñ—è–∂ —ñ –∑–∞—á—ñ—Å–∫—É!\n",
            "üì∏ i want to take a photo as ...\n",
            " under no circumstances should you compare yourself to someone or imitate someone. we are all different from nature and if one image is 100 percent, the other may not see himself as beautiful. we are looking for something that suits only you!\n",
            " üì∏the image does not match the party!\n",
            " often you do not like yourself in the photo not because you did poorly in the frame, but because your clothes just do not match the style of the chosen location. always discuss this point with the photographer, she / he will always be happy to tell you something and pick up clothes for the photo studio.\n",
            " carefully choose the images for a photo shoot, makeup and hair!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization"
      ],
      "metadata": {
        "id": "oJCzoq0iADTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uk_tokens = nltk.word_tokenize(uk_text)\n",
        "en_tokens = nltk.word_tokenize(en_text)\n",
        "print(uk_tokens)\n",
        "print(en_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTjcvgC--kJJ",
        "outputId": "61e3a4a0-dbb1-4474-a1ed-847169bcb62d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['üì∏', '—Ö–æ—á—É', '–≤–∏–π—Ç–∏', '–Ω–∞', '—Ñ–æ—Ç–æ', '—è–∫', '...', '–Ω—ñ', '–≤', '—è–∫–æ–º—É', '—Ä–∞–∑—ñ', '–Ω–µ', '–ø–æ—Ç—Ä—ñ–±–Ω–æ', '–ø–æ—Ä—ñ–≤–Ω—é–≤–∞—Ç–∏', '—Å–µ–±–µ', '–∑', '–∫–∏–º–æ—Å—å', '–∞–±–æ', '–∫–æ–≥–æ—Å—å', '–Ω–∞—Å–ª—ñ–¥—É–≤–∞—Ç–∏', '.', '–≤—Å—ñ', '–º–∏', '—Ä—ñ–∑–Ω—ñ', '–≤—ñ–¥', '–ø—Ä–∏—Ä–æ–¥–∏', '—ñ', '—è–∫—â–æ', '–æ–¥–Ω–æ–º—É', '–æ–±—Ä–∞–∑', '–π–¥–µ', '–Ω–∞', '100', '–≤—ñ–¥—Å–æ—Ç–∫—ñ–≤', ',', '—Ç–æ', '—ñ–Ω—à–∏–π', '–≤', '–Ω—å–æ–º—É', '–º–æ–∂–µ', '–ø–æ–±–∞—á–∏—Ç–∏', '—Å–µ–±–µ', '–Ω–µ', '–∫—Ä–∞—Å–∏–≤–∏–º', '.', '—à—É–∫–∞—î–º–æ', '—Ç–æ', '—â–æ', '–π–¥–µ', '—Ç—ñ–ª—å–∫–∏', '–≤–∞–º', '!', 'üì∏–æ–±—Ä–∞–∑', '–Ω–µ', '–≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î', '—Å—Ç–æ—Ä–æ–Ω–∏', '!', '—á–∞—Å—Ç–æ', '–≤–∏', '–Ω–µ', '–ø–æ–¥–æ–±–∞—î—Ç–µ—Å—è', '—Å–æ–±—ñ', '–Ω–∞', '—Ñ–æ—Ç–æ', '–Ω–µ', '—Ç–æ–º—É', '—â–æ', '–≤–∏', '–ø–æ–≥–∞–Ω–æ', '–≤–∏–π—à–ª–∏', '–≤', '–∫–∞–¥—Ä—ñ', ',', '–∞', '—Ç–æ–º—É', '—â–æ', '–ø—Ä–æ—Å—Ç–æ', '–≤–∞—à', '–æ–¥—è–≥', '–∞–±—Å–æ–ª—é—Ç–Ω–æ', '–Ω–µ', '–≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î', '—Å—Ç–∏–ª—é', '–æ–±—Ä–∞–Ω–æ—ó', '–ª–æ–∫–∞—Ü—ñ—ó', '.', '–∑–∞–≤–∂–¥–∏', '–æ–±–≥–æ–≤–æ—Ä—é–π—Ç–µ', '—Ü–µ–π', '–º–æ–º–µ–Ω—Ç', '–∑', '—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–æ–º', ',', '–≤–æ–Ω–∞', '/', '–≤—ñ–Ω', '–∑–∞–≤–∂–¥–∏', '–∑', '—Ä–∞–¥—ñ—Å—Ç—é', '–≤–∞–º', '—â–æ—Å—å', '–ø—ñ–¥–∫–∞–∂–µ', '—ñ', '–ø—ñ–¥–±–µ—Ä–µ', '–æ–¥—è–≥', '–¥–æ', '—Ñ–æ—Ç–æ—Å—Ç—É–¥—ñ—ó', '.', '—Ä–µ—Ç–µ–ª—å–Ω–æ', '–ø—ñ–¥–±–∏—Ä–∞–π—Ç–µ', '–æ–±—Ä–∞–∑–∏', '–Ω–∞', '—Ñ–æ—Ç–æ—Å–µ—Å—ñ—é', ',', '–º–∞–∫—ñ—è–∂', '—ñ', '–∑–∞—á—ñ—Å–∫—É', '!']\n",
            "['üì∏', 'i', 'want', 'to', 'take', 'a', 'photo', 'as', '...', 'under', 'no', 'circumstances', 'should', 'you', 'compare', 'yourself', 'to', 'someone', 'or', 'imitate', 'someone', '.', 'we', 'are', 'all', 'different', 'from', 'nature', 'and', 'if', 'one', 'image', 'is', '100', 'percent', ',', 'the', 'other', 'may', 'not', 'see', 'himself', 'as', 'beautiful', '.', 'we', 'are', 'looking', 'for', 'something', 'that', 'suits', 'only', 'you', '!', 'üì∏the', 'image', 'does', 'not', 'match', 'the', 'party', '!', 'often', 'you', 'do', 'not', 'like', 'yourself', 'in', 'the', 'photo', 'not', 'because', 'you', 'did', 'poorly', 'in', 'the', 'frame', ',', 'but', 'because', 'your', 'clothes', 'just', 'do', 'not', 'match', 'the', 'style', 'of', 'the', 'chosen', 'location', '.', 'always', 'discuss', 'this', 'point', 'with', 'the', 'photographer', ',', 'she', '/', 'he', 'will', 'always', 'be', 'happy', 'to', 'tell', 'you', 'something', 'and', 'pick', 'up', 'clothes', 'for', 'the', 'photo', 'studio', '.', 'carefully', 'choose', 'the', 'images', 'for', 'a', 'photo', 'shoot', ',', 'makeup', 'and', 'hair', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding frequency distinct in the text"
      ],
      "metadata": {
        "id": "slujjvbKBoI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uk_freq_dist = nltk.probability.FreqDist(uk_tokens)\n",
        "en_freq_dist = nltk.probability.FreqDist(en_tokens)\n",
        "print(uk_freq_dist)\n",
        "print(en_freq_dist)\n",
        "print(uk_freq_dist.most_common(10))\n",
        "print(en_freq_dist.most_common(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWrOxe89Bj2D",
        "outputId": "b8e9d1b0-1fa9-4916-caf5-7ac178ba91ac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<FreqDist with 84 samples and 118 outcomes>\n",
            "<FreqDist with 90 samples and 137 outcomes>\n",
            "[('–Ω–µ', 6), ('–Ω–∞', 4), ('.', 4), (',', 4), ('–≤', 3), ('–∑', 3), ('—ñ', 3), ('—â–æ', 3), ('!', 3), ('—Ñ–æ—Ç–æ', 2)]\n",
            "[('the', 9), ('you', 5), ('not', 5), ('photo', 4), ('.', 4), (',', 4), ('to', 3), ('and', 3), ('for', 3), ('!', 3)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete stop words"
      ],
      "metadata": {
        "id": "g7NBp-vgC7w6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "en_stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "uk_stop_words = set(read_text('stopwords-uk.txt').split())\n",
        "print(en_stop_words)\n",
        "print(uk_stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVNGTqQNC7ZM",
        "outputId": "9a60126b-c55c-4131-d3ad-efe02b404b8d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'these', 'was', 'while', 'some', 'no', 'i', 'ours', 'during', \"should've\", 'where', 'from', 'each', 'were', \"aren't\", 'those', 'ma', \"you'll\", 'her', 'hadn', 'and', 're', \"hasn't\", 'ain', 'y', 'few', 'with', 'over', 'been', 'down', 'its', 'until', 'out', 'how', \"don't\", 'now', 'd', 'any', 'in', 'by', 'not', 'aren', 'haven', 'needn', 'if', 'shan', 'being', 'their', 'only', 'all', 'didn', 'who', 'than', 'the', 'above', 'wasn', 'have', 'up', 'won', 'but', 'as', 'mustn', 'of', 'me', 'couldn', 'off', 'it', 'very', 'once', 'weren', 's', 'because', 'him', 'our', 'shouldn', \"it's\", 'themselves', 'he', 'isn', \"wouldn't\", 'such', 'under', 'why', 'most', 'is', 'doing', \"mustn't\", 'do', 'wouldn', 'am', \"doesn't\", \"hadn't\", 'to', 'himself', 'both', 'own', 'about', 'theirs', 'yourself', 'too', 'his', 'after', 'can', \"shan't\", 'for', 'doesn', \"needn't\", 'or', \"that'll\", 'you', 'whom', 'ourselves', \"you'd\", 'll', \"you're\", 'there', 'into', 'nor', 'does', 'through', 'again', 'hasn', 'hers', \"weren't\", \"wasn't\", 'here', 'm', 'herself', 'yourselves', 'which', 'when', 'yours', 've', 'further', 'mightn', \"you've\", 'will', 'at', 'a', 'she', 'itself', 'your', 'are', \"haven't\", 'did', 'an', 'o', 'below', 'between', 'just', \"mightn't\", 'has', \"shouldn't\", 'same', 'should', 't', 'don', 'then', 'against', 'they', 'be', \"didn't\", 'had', 'them', 'more', 'my', \"won't\", 'having', \"couldn't\", 'so', 'myself', 'on', 'other', 'we', 'this', \"she's\", 'before', \"isn't\", 'what', 'that'}\n",
            "{'–∑–∞–º—ñ—Å—Ç—å', '–ª–µ–¥–≤–µ', '–æ—Ç–æ–∂', '–ø–æ–∑–∞', '—Ü–µ', '—è–∫–∏–π', '–¥–∞', '–≤—ñ–Ω', '—Ç–∞–∫', '–º–∏', '–≤—ñ–¥', '–∞–¥–∂–µ', '–¥–æ', '–π', '–∫–æ–ª–∏', '–ø—Ä–æ', '–ø—ñ–¥', '–≤–Ω–∏–∑', '—Ç–∞–∫–æ–∂', '–≤–µ—Å—å', '—Ü–µ–π', '–Ω–∞–º', '–±—É–ª–∏', '–¥–ª—è', '—Ç–æ–±—Ç–æ', '–≤—Å–µ', '—è–∫', '–±—É–≤', '–Ω–∞–≤–∫–æ–ª–æ', '–≤–∞–º', '—î', '–≤–æ–Ω–æ', '–∑–∞–≤–∂–¥–∏', '–Ω–∞–≤—ñ—Ç—å', '–æ—Ç', '–¥–µ', '–±—ñ–ª—å—à', '–±—É—Ç–∏', '—á–æ–≥–æ', '–∑', '–∞–ª–µ', '—Ç–µ', '–±', '–±—É–ª–∞', '–æ—Ç–∂–µ', '—ó—ó', '–≤–æ–Ω–∞', '–¥–∞–≤–∞–π', '—Ç–∏', '—ó—Ö', '–¥–∞–≤–∞—Ç–∏', '–≤–∑–¥–æ–≤–∂', '—á–∏', '–≤—Å–µ—Ä–µ–¥–∏–Ω—ñ', '–≤–∞—Å', '—â–æ', '—Ç–∞–∫–∏–π', '—è–∫–æ—ó', '–≤–æ–Ω–∏', '–≤–Ω–∏–∑—É', '–≤—Å—ñ—Ö', '–±–µ–∑', '—ñ–∑', '—Ç–æ—â–æ', '—ñ–Ω—à–∏—Ö', '–±—É–ª–æ', '–¥–µ—â–æ', '–∞–≤–∂–µ–∂', '–º–∞–π–∂–µ', '—Ç–∞', '–≤–∏', '—Ö–æ—á–∞', '—Ç–æ–∂'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming"
      ],
      "metadata": {
        "id": "3lnDZaa8JVHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UkStemmer():\n",
        "    def __init__(self):\n",
        "        self.vowel = r'–∞–µ–∏–æ—É—é—è—ñ—ó—î' \n",
        "        self.perfectiveground = r'(–∏–≤|–∏–≤—à–∏|–∏–≤—à–∏—Å—å|—ã–≤|—ã–≤—à–∏|—ã–≤—à–∏—Å—å((?<=[–∞—è])(–≤|–≤—à–∏|–≤—à–∏—Å—å)))$'\n",
        "        self.reflexive = r'(—Å[—è—å–∏])$'\n",
        "        self.adjective = r'(–∏–º–∏|—ñ–π|–∏–π|–∞|–µ|–æ–≤–∞|–æ–≤–µ|—ñ–≤|—î|—ó–π|—î—î|–µ—î|—è|—ñ–º|–µ–º|–∏–º|—ñ–º|–∏—Ö|—ñ—Ö|–æ—é|–π–º–∏|—ñ–º–∏|—É|—é|–æ–≥–æ|–æ–º—É|–æ—ó)$'\n",
        "        self.participle = r'(–∏–π|–æ–≥–æ|–æ–º—É|–∏–º|—ñ–º|–∞|—ñ–π|—É|–æ—é|—ñ–π|—ñ|–∏—Ö|–π–º–∏|–∏—Ö)$'\n",
        "        self.verb = r'(—Å—å|—Å—è|–∏–≤|–∞—Ç—å|—è—Ç—å|—É|—é|–∞–≤|–∞–ª–∏|—É—á–∏|—è—á–∏|–≤—à–∏|—à–∏|–µ|–º–µ|–∞—Ç–∏|—è—Ç–∏|—î)$'\n",
        "        self.noun = r'(–∞|–µ–≤|–æ–≤|–µ|—è–º–∏|–∞–º–∏|–µ–∏|–∏|–µ–π|–æ–π|–∏–π|–π|–∏—è–º|—è–º|–∏–µ–º|–µ–º|–∞–º|–æ–º|–æ|—É|–∞—Ö|–∏—è—Ö|—è—Ö|—ã|—å|–∏—é|—å—é|—é|–∏—è|—å—è|—è|—ñ|–æ–≤—ñ|—ó|–µ—é|—î—é|–æ—é|—î|–µ–≤—ñ|–µ–º|—î–º|—ñ–≤|—ó–≤|—é)$'\n",
        "        self.rvre = r'[–∞–µ–∏–æ—É—é—è—ñ—ó—î]'\n",
        "        self.derivational = r'[^–∞–µ–∏–æ—É—é—è—ñ—ó—î][–∞–µ–∏–æ—É—é—è—ñ—ó—î]+[^–∞–µ–∏–æ—É—é—è—ñ—ó—î]+[–∞–µ–∏–æ—É—é—è—ñ—ó—î].*(?<=–æ)—Å—Ç—å?$'\n",
        "        self.RV = ''\n",
        "\n",
        "    def ukstemmer_search_preprocess(self, word):\n",
        "        word = word.lower()\n",
        "        word = word.replace(\"'\", \"\")\n",
        "        word = word.replace(\"—ë\", \"–µ\")\n",
        "        word = word.replace(\"—ä\", \"—ó\")\n",
        "        return word\n",
        "\n",
        "    def s(self, st, reg, to):\n",
        "        orig = st\n",
        "        self.RV = re.sub(reg, to, st)\n",
        "        return (orig != self.RV)\n",
        "\n",
        "    def stem_word(self, word):\n",
        "        self.word = word\n",
        "        word = self.ukstemmer_search_preprocess(self.word)\n",
        "        if not re.search('[–∞–µ–∏–æ—É—é—è—ñ—ó—î]', word):\n",
        "            stem = word\n",
        "        else:\n",
        "            p = re.search(self.rvre, word)\n",
        "            start = word[0:p.span()[1]]\n",
        "            self.RV = word[p.span()[1]:]\n",
        "\n",
        "            if not self.s(self.RV, self.perfectiveground, ''):\n",
        "\n",
        "                self.s(self.RV, self.reflexive, '')\n",
        "                if self.s(self.RV, self.adjective, ''):\n",
        "                    self.s(self.RV, self.participle, '')\n",
        "                else:\n",
        "                    if not self.s(self.RV, self.verb, ''):\n",
        "                        self.s(self.RV, self.noun, '')\n",
        "\n",
        "            self.s(self.RV, '–∏$', '')\n",
        "\n",
        "            if re.search(self.derivational, self.RV):\n",
        "                self.s(self.RV, '–æ—Å—Ç—å$', '')\n",
        "\n",
        "            if self.s(self.RV, '—å$', ''):\n",
        "                self.s(self.RV, '–µ–π—à–µ?$', '')\n",
        "                self.s(self.RV, '–Ω–Ω$', u'–Ω')\n",
        "\n",
        "            stem = start + self.RV\n",
        "        return stem"
      ],
      "metadata": {
        "id": "Yr8BQEeYKxVm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_stemmer = nltk.stem.PorterStemmer()\n",
        "en_stem_words = [en_stemmer.stem(word) for word in en_tokens]\n",
        "uk_stemmer = UkStemmer()\n",
        "uk_stem_words = [uk_stemmer.stem_word(word) for word in uk_tokens]\n",
        "print(en_stem_words)\n",
        "print(uk_stem_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNs5o0G4JW_o",
        "outputId": "19f2e9fd-66c0-4333-e658-01072dd37ff8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['üì∏', 'i', 'want', 'to', 'take', 'a', 'photo', 'as', '...', 'under', 'no', 'circumst', 'should', 'you', 'compar', 'yourself', 'to', 'someon', 'or', 'imit', 'someon', '.', 'we', 'are', 'all', 'differ', 'from', 'natur', 'and', 'if', 'one', 'imag', 'is', '100', 'percent', ',', 'the', 'other', 'may', 'not', 'see', 'himself', 'as', 'beauti', '.', 'we', 'are', 'look', 'for', 'someth', 'that', 'suit', 'onli', 'you', '!', 'üì∏the', 'imag', 'doe', 'not', 'match', 'the', 'parti', '!', 'often', 'you', 'do', 'not', 'like', 'yourself', 'in', 'the', 'photo', 'not', 'becaus', 'you', 'did', 'poorli', 'in', 'the', 'frame', ',', 'but', 'becaus', 'your', 'cloth', 'just', 'do', 'not', 'match', 'the', 'style', 'of', 'the', 'chosen', 'locat', '.', 'alway', 'discuss', 'thi', 'point', 'with', 'the', 'photograph', ',', 'she', '/', 'he', 'will', 'alway', 'be', 'happi', 'to', 'tell', 'you', 'someth', 'and', 'pick', 'up', 'cloth', 'for', 'the', 'photo', 'studio', '.', 'care', 'choos', 'the', 'imag', 'for', 'a', 'photo', 'shoot', ',', 'makeup', 'and', 'hair', '!']\n",
            "['üì∏', '—Ö–æ—á', '–≤–∏–π—Ç', '–Ω–∞', '—Ñ–æ—Ç', '—è–∫', '...', '–Ω—ñ', '–≤', '—è–∫', '—Ä–∞–∑', '–Ω–µ', '–ø–æ—Ç—Ä—ñ–±–Ω', '–ø–æ—Ä—ñ–≤–Ω—é–≤', '—Å–µ–±', '–∑', '–∫–∏–º', '–∞–±', '–∫–æ–≥', '–Ω–∞—Å–ª—ñ–¥—É–≤', '.', '–≤—Å—ñ', '–º–∏', '—Ä—ñ–∑–Ω', '–≤—ñ–¥', '–ø—Ä–∏—Ä–æ–¥', '—ñ', '—è–∫—â', '–æ–¥–Ω', '–æ–±—Ä–∞–∑', '–π–¥–µ', '–Ω–∞', '100', '–≤—ñ–¥—Å–æ—Ç–∫', ',', '—Ç–æ', '—ñ–Ω—à', '–≤', '–Ω—å–æ–º', '–º–æ–∂', '–ø–æ–±–∞—á–∏—Ç', '—Å–µ–±', '–Ω–µ', '–∫—Ä–∞—Å–∏–≤', '.', '—à—É–∫–∞—î–º', '—Ç–æ', '—â–æ', '–π–¥–µ', '—Ç—ñ–ª—å–∫', '–≤–∞–º', '!', 'üì∏–æ–±—Ä–∞–∑', '–Ω–µ', '–≤—ñ–¥–ø–æ–≤—ñ–¥', '—Å—Ç–æ—Ä–æ–Ω', '!', '—á–∞—Å—Ç', '–≤–∏', '–Ω–µ', '–ø–æ–¥–æ–±–∞—î—Ç', '—Å–æ–±', '–Ω–∞', '—Ñ–æ—Ç', '–Ω–µ', '—Ç–æ–º', '—â–æ', '–≤–∏', '–ø–æ–≥–∞–Ω', '–≤–∏–π—à–ª', '–≤', '–∫–∞–¥—Ä', ',', '–∞', '—Ç–æ–º', '—â–æ', '–ø—Ä–æ—Å—Ç', '–≤–∞—à', '–æ–¥—è–≥', '–∞–±—Å–æ–ª—é—Ç–Ω', '–Ω–µ', '–≤—ñ–¥–ø–æ–≤—ñ–¥', '—Å—Ç–∏–ª', '–æ–±—Ä–∞–Ω', '–ª–æ–∫–∞—Ü—ñ', '.', '–∑–∞–≤–∂–¥', '–æ–±–≥–æ–≤–æ—Ä—é–π—Ç', '—Ü–µ', '–º–æ–º–µ–Ω—Ç', '–∑', '—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ', ',', '–≤–æ–Ω', '/', '–≤—ñ–Ω', '–∑–∞–≤–∂–¥', '–∑', '—Ä–∞–¥—ñ—Å—Ç', '–≤–∞–º', '—â–æ', '–ø—ñ–¥–∫–∞–∂', '—ñ', '–ø—ñ–¥–±–µ—Ä', '–æ–¥—è–≥', '–¥–æ', '—Ñ–æ—Ç–æ—Å—Ç—É–¥—ñ', '.', '—Ä–µ—Ç–µ–ª—å–Ω', '–ø—ñ–¥–±–∏—Ä–∞–π—Ç', '–æ–±—Ä–∞–∑', '–Ω–∞', '—Ñ–æ—Ç–æ—Å–µ—Å', ',', '–º–∞–∫—ñ—è–∂', '—ñ', '–∑–∞—á—ñ—Å–∫', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part of speech tagging"
      ],
      "metadata": {
        "id": "HAReVFh1LWQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "en_pos_tag = [nltk.pos_tag([token]) for token in en_tokens]\n",
        "print(en_pos_tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxWe2TNkLWog",
        "outputId": "05c048a6-6222-4d09-d5d4-d328d948737e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[('üì∏', 'NN')], [('i', 'NN')], [('want', 'NN')], [('to', 'TO')], [('take', 'VB')], [('a', 'DT')], [('photo', 'NN')], [('as', 'IN')], [('...', ':')], [('under', 'IN')], [('no', 'DT')], [('circumstances', 'NNS')], [('should', 'MD')], [('you', 'PRP')], [('compare', 'NN')], [('yourself', 'PRP')], [('to', 'TO')], [('someone', 'NN')], [('or', 'CC')], [('imitate', 'NN')], [('someone', 'NN')], [('.', '.')], [('we', 'PRP')], [('are', 'VBP')], [('all', 'DT')], [('different', 'JJ')], [('from', 'IN')], [('nature', 'NN')], [('and', 'CC')], [('if', 'IN')], [('one', 'CD')], [('image', 'NN')], [('is', 'VBZ')], [('100', 'CD')], [('percent', 'NN')], [(',', ',')], [('the', 'DT')], [('other', 'JJ')], [('may', 'MD')], [('not', 'RB')], [('see', 'VB')], [('himself', 'PRP')], [('as', 'IN')], [('beautiful', 'NN')], [('.', '.')], [('we', 'PRP')], [('are', 'VBP')], [('looking', 'VBG')], [('for', 'IN')], [('something', 'NN')], [('that', 'IN')], [('suits', 'NNS')], [('only', 'RB')], [('you', 'PRP')], [('!', '.')], [('üì∏the', 'NN')], [('image', 'NN')], [('does', 'VBZ')], [('not', 'RB')], [('match', 'NN')], [('the', 'DT')], [('party', 'NN')], [('!', '.')], [('often', 'RB')], [('you', 'PRP')], [('do', 'VB')], [('not', 'RB')], [('like', 'IN')], [('yourself', 'PRP')], [('in', 'IN')], [('the', 'DT')], [('photo', 'NN')], [('not', 'RB')], [('because', 'IN')], [('you', 'PRP')], [('did', 'VBD')], [('poorly', 'RB')], [('in', 'IN')], [('the', 'DT')], [('frame', 'NN')], [(',', ',')], [('but', 'CC')], [('because', 'IN')], [('your', 'PRP$')], [('clothes', 'NNS')], [('just', 'RB')], [('do', 'VB')], [('not', 'RB')], [('match', 'NN')], [('the', 'DT')], [('style', 'NN')], [('of', 'IN')], [('the', 'DT')], [('chosen', 'NN')], [('location', 'NN')], [('.', '.')], [('always', 'RB')], [('discuss', 'NN')], [('this', 'DT')], [('point', 'NN')], [('with', 'IN')], [('the', 'DT')], [('photographer', 'NN')], [(',', ',')], [('she', 'PRP')], [('/', 'NN')], [('he', 'PRP')], [('will', 'MD')], [('always', 'RB')], [('be', 'VB')], [('happy', 'JJ')], [('to', 'TO')], [('tell', 'NN')], [('you', 'PRP')], [('something', 'NN')], [('and', 'CC')], [('pick', 'NN')], [('up', 'RB')], [('clothes', 'NNS')], [('for', 'IN')], [('the', 'DT')], [('photo', 'NN')], [('studio', 'NN')], [('.', '.')], [('carefully', 'RB')], [('choose', 'NN')], [('the', 'DT')], [('images', 'NNS')], [('for', 'IN')], [('a', 'DT')], [('photo', 'NN')], [('shoot', 'NN')], [(',', ',')], [('makeup', 'NN')], [('and', 'CC')], [('hair', 'NN')], [('!', '.')]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tagger import Tagger"
      ],
      "metadata": {
        "id": "u4KIHeWtPoSj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uk_tag = Tagger(uk_tokens)\n",
        "uk_tag.label_data()"
      ],
      "metadata": {
        "id": "tOBbcMCaSkvn"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uk_pos_tag = [(uk_tokens[i], uk_tag.predicted_tags[i][0]) for i in  range(0, len(uk_tokens))]\n",
        "print(uk_pos_tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJYyyz6Qjzov",
        "outputId": "3c047735-34f9-479a-aab2-14c1dc250d78"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('üì∏', 'NOUN'), ('—Ö–æ—á—É', 'SCONJ'), ('–≤–∏–π—Ç–∏', 'VERB'), ('–Ω–∞', 'ADP'), ('—Ñ–æ—Ç–æ', 'NOUN'), ('—è–∫', 'DET'), ('...', 'PUNCT'), ('–Ω—ñ', 'PART'), ('–≤', 'ADP'), ('—è–∫–æ–º—É', 'DET'), ('—Ä–∞–∑—ñ', 'NOUN'), ('–Ω–µ', 'PART'), ('–ø–æ—Ç—Ä—ñ–±–Ω–æ', 'ADV'), ('–ø–æ—Ä—ñ–≤–Ω—é–≤–∞—Ç–∏', 'NOUN'), ('—Å–µ–±–µ', 'PRON'), ('–∑', 'ADP'), ('–∫–∏–º–æ—Å—å', 'PRON'), ('–∞–±–æ', 'CCONJ'), ('–∫–æ–≥–æ—Å—å', 'PRON'), ('–Ω–∞—Å–ª—ñ–¥—É–≤–∞—Ç–∏', 'VERB'), ('.', 'PUNCT'), ('–≤—Å—ñ', 'DET'), ('–º–∏', 'PRON'), ('—Ä—ñ–∑–Ω—ñ', 'ADJ'), ('–≤—ñ–¥', 'ADP'), ('–ø—Ä–∏—Ä–æ–¥–∏', 'NOUN'), ('—ñ', 'CCONJ'), ('—è–∫—â–æ', 'SCONJ'), ('–æ–¥–Ω–æ–º—É', 'DET'), ('–æ–±—Ä–∞–∑', 'NOUN'), ('–π–¥–µ', 'VERB'), ('–Ω–∞', 'ADP'), ('100', 'NUM'), ('–≤—ñ–¥—Å–æ—Ç–∫—ñ–≤', 'NOUN'), (',', 'PUNCT'), ('—Ç–æ', 'PART'), ('—ñ–Ω—à–∏–π', 'DET'), ('–≤', 'ADP'), ('–Ω—å–æ–º—É', 'PRON'), ('–º–æ–∂–µ', 'VERB'), ('–ø–æ–±–∞—á–∏—Ç–∏', 'VERB'), ('—Å–µ–±–µ', 'PRON'), ('–Ω–µ', 'PART'), ('–∫—Ä–∞—Å–∏–≤–∏–º', 'ADJ'), ('.', 'PUNCT'), ('—à—É–∫–∞—î–º–æ', 'SYM'), ('—Ç–æ', 'DET'), ('—â–æ', 'PRON'), ('–π–¥–µ', 'VERB'), ('—Ç—ñ–ª—å–∫–∏', 'PART'), ('–≤–∞–º', 'PRON'), ('!', 'PUNCT'), ('üì∏–æ–±—Ä–∞–∑', 'X'), ('–Ω–µ', 'PART'), ('–≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î', 'VERB'), ('—Å—Ç–æ—Ä–æ–Ω–∏', 'NOUN'), ('!', 'PUNCT'), ('—á–∞—Å—Ç–æ', 'ADV'), ('–≤–∏', 'PRON'), ('–Ω–µ', 'PART'), ('–ø–æ–¥–æ–±–∞—î—Ç–µ—Å—è', 'VERB'), ('—Å–æ–±—ñ', 'PRON'), ('–Ω–∞', 'ADP'), ('—Ñ–æ—Ç–æ', 'NOUN'), ('–Ω–µ', 'PART'), ('—Ç–æ–º—É', 'ADV'), ('—â–æ', 'PRON'), ('–≤–∏', 'PRON'), ('–ø–æ–≥–∞–Ω–æ', 'ADV'), ('–≤–∏–π—à–ª–∏', 'VERB'), ('–≤', 'ADP'), ('–∫–∞–¥—Ä—ñ', 'NOUN'), (',', 'PUNCT'), ('–∞', 'CCONJ'), ('—Ç–æ–º—É', 'ADV'), ('—â–æ', 'PRON'), ('–ø—Ä–æ—Å—Ç–æ', 'PART'), ('–≤–∞—à', 'DET'), ('–æ–¥—è–≥', 'NOUN'), ('–∞–±—Å–æ–ª—é—Ç–Ω–æ', 'ADV'), ('–Ω–µ', 'PART'), ('–≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î', 'VERB'), ('—Å—Ç–∏–ª—é', 'NOUN'), ('–æ–±—Ä–∞–Ω–æ—ó', 'NOUN'), ('–ª–æ–∫–∞—Ü—ñ—ó', 'NOUN'), ('.', 'PUNCT'), ('–∑–∞–≤–∂–¥–∏', 'ADV'), ('–æ–±–≥–æ–≤–æ—Ä—é–π—Ç–µ', 'NOUN'), ('—Ü–µ–π', 'PRON'), ('–º–æ–º–µ–Ω—Ç', 'NOUN'), ('–∑', 'ADP'), ('—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–æ–º', 'NOUN'), (',', 'PUNCT'), ('–≤–æ–Ω–∞', 'PRON'), ('/', 'PROPN'), ('–≤—ñ–Ω', 'PRON'), ('–∑–∞–≤–∂–¥–∏', 'ADV'), ('–∑', 'ADP'), ('—Ä–∞–¥—ñ—Å—Ç—é', 'NOUN'), ('–≤–∞–º', 'PRON'), ('—â–æ—Å—å', 'SCONJ'), ('–ø—ñ–¥–∫–∞–∂–µ', 'VERB'), ('—ñ', 'CCONJ'), ('–ø—ñ–¥–±–µ—Ä–µ', 'VERB'), ('–æ–¥—è–≥', 'VERB'), ('–¥–æ', 'ADP'), ('—Ñ–æ—Ç–æ—Å—Ç—É–¥—ñ—ó', 'NOUN'), ('.', 'PUNCT'), ('—Ä–µ—Ç–µ–ª—å–Ω–æ', 'SYM'), ('–ø—ñ–¥–±–∏—Ä–∞–π—Ç–µ', 'NOUN'), ('–æ–±—Ä–∞–∑–∏', 'NOUN'), ('–Ω–∞', 'ADP'), ('—Ñ–æ—Ç–æ—Å–µ—Å—ñ—é', 'NOUN'), (',', 'PUNCT'), ('–º–∞–∫—ñ—è–∂', 'NOUN'), ('—ñ', 'CCONJ'), ('–∑–∞—á—ñ—Å–∫—É', 'NOUN'), ('!', 'PUNCT')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chunking"
      ],
      "metadata": {
        "id": "E7qX0XZAktNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg = \"NP: {<DT>?<JJ>*<NN>}\"\n",
        "en_pos_tag = nltk.pos_tag(en_tokens)\n",
        "reg_parser = nltk.RegexpParser(reg)\n",
        "result = reg_parser.parse(en_pos_tag)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e71L7aWLktsb",
        "outputId": "8e832d5b-9c45-4f24-e72a-00e14e2c6d39"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP üì∏/NN)\n",
            "  (NP i/NN)\n",
            "  want/VBP\n",
            "  to/TO\n",
            "  take/VB\n",
            "  (NP a/DT photo/NN)\n",
            "  as/IN\n",
            "  .../:\n",
            "  under/IN\n",
            "  no/DT\n",
            "  circumstances/NNS\n",
            "  should/MD\n",
            "  you/PRP\n",
            "  compare/VB\n",
            "  yourself/PRP\n",
            "  to/TO\n",
            "  (NP someone/NN)\n",
            "  or/CC\n",
            "  imitate/VB\n",
            "  (NP someone/NN)\n",
            "  ./.\n",
            "  we/PRP\n",
            "  are/VBP\n",
            "  all/DT\n",
            "  different/JJ\n",
            "  from/IN\n",
            "  (NP nature/NN)\n",
            "  and/CC\n",
            "  if/IN\n",
            "  one/CD\n",
            "  (NP image/NN)\n",
            "  is/VBZ\n",
            "  100/CD\n",
            "  (NP percent/NN)\n",
            "  ,/,\n",
            "  the/DT\n",
            "  other/JJ\n",
            "  may/MD\n",
            "  not/RB\n",
            "  see/VB\n",
            "  himself/PRP\n",
            "  as/IN\n",
            "  (NP beautiful/NN)\n",
            "  ./.\n",
            "  we/PRP\n",
            "  are/VBP\n",
            "  looking/VBG\n",
            "  for/IN\n",
            "  (NP something/NN)\n",
            "  that/WDT\n",
            "  suits/NNS\n",
            "  only/RB\n",
            "  you/PRP\n",
            "  !/.\n",
            "  (NP üì∏the/JJ image/NN)\n",
            "  does/VBZ\n",
            "  not/RB\n",
            "  match/VB\n",
            "  (NP the/DT party/NN)\n",
            "  !/.\n",
            "  often/RB\n",
            "  you/PRP\n",
            "  do/VBP\n",
            "  not/RB\n",
            "  like/VB\n",
            "  yourself/PRP\n",
            "  in/IN\n",
            "  (NP the/DT photo/NN)\n",
            "  not/RB\n",
            "  because/IN\n",
            "  you/PRP\n",
            "  did/VBD\n",
            "  poorly/RB\n",
            "  in/IN\n",
            "  (NP the/DT frame/NN)\n",
            "  ,/,\n",
            "  but/CC\n",
            "  because/IN\n",
            "  your/PRP$\n",
            "  clothes/NNS\n",
            "  just/RB\n",
            "  do/VBP\n",
            "  not/RB\n",
            "  match/VB\n",
            "  (NP the/DT style/NN)\n",
            "  of/IN\n",
            "  (NP the/DT chosen/NN)\n",
            "  (NP location/NN)\n",
            "  ./.\n",
            "  always/RB\n",
            "  discuss/VB\n",
            "  (NP this/DT point/NN)\n",
            "  with/IN\n",
            "  (NP the/DT photographer/NN)\n",
            "  ,/,\n",
            "  she/PRP\n",
            "  //VBD\n",
            "  he/PRP\n",
            "  will/MD\n",
            "  always/RB\n",
            "  be/VB\n",
            "  happy/JJ\n",
            "  to/TO\n",
            "  tell/VB\n",
            "  you/PRP\n",
            "  (NP something/NN)\n",
            "  and/CC\n",
            "  pick/VB\n",
            "  up/RP\n",
            "  clothes/NNS\n",
            "  for/IN\n",
            "  (NP the/DT photo/NN)\n",
            "  (NP studio/NN)\n",
            "  ./.\n",
            "  carefully/RB\n",
            "  choose/VB\n",
            "  the/DT\n",
            "  images/NNS\n",
            "  for/IN\n",
            "  (NP a/DT photo/NN)\n",
            "  (NP shoot/NN)\n",
            "  ,/,\n",
            "  (NP makeup/NN)\n",
            "  and/CC\n",
            "  (NP hair/NN)\n",
            "  !/.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg = \"NP: {<DT>?<JJ>*<NN>}\"\n",
        "reg_parser = nltk.RegexpParser(reg)\n",
        "result = reg_parser.parse(uk_pos_tag)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC5c1ivCnbBu",
        "outputId": "39c380a3-4a50-4fec-b06f-f9a35637e67c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  üì∏/NOUN\n",
            "  —Ö–æ—á—É/SCONJ\n",
            "  –≤–∏–π—Ç–∏/VERB\n",
            "  –Ω–∞/ADP\n",
            "  —Ñ–æ—Ç–æ/NOUN\n",
            "  —è–∫/DET\n",
            "  .../PUNCT\n",
            "  –Ω—ñ/PART\n",
            "  –≤/ADP\n",
            "  —è–∫–æ–º—É/DET\n",
            "  —Ä–∞–∑—ñ/NOUN\n",
            "  –Ω–µ/PART\n",
            "  –ø–æ—Ç—Ä—ñ–±–Ω–æ/ADV\n",
            "  –ø–æ—Ä—ñ–≤–Ω—é–≤–∞—Ç–∏/NOUN\n",
            "  —Å–µ–±–µ/PRON\n",
            "  –∑/ADP\n",
            "  –∫–∏–º–æ—Å—å/PRON\n",
            "  –∞–±–æ/CCONJ\n",
            "  –∫–æ–≥–æ—Å—å/PRON\n",
            "  –Ω–∞—Å–ª—ñ–¥—É–≤–∞—Ç–∏/VERB\n",
            "  ./PUNCT\n",
            "  –≤—Å—ñ/DET\n",
            "  –º–∏/PRON\n",
            "  —Ä—ñ–∑–Ω—ñ/ADJ\n",
            "  –≤—ñ–¥/ADP\n",
            "  –ø—Ä–∏—Ä–æ–¥–∏/NOUN\n",
            "  —ñ/CCONJ\n",
            "  —è–∫—â–æ/SCONJ\n",
            "  –æ–¥–Ω–æ–º—É/DET\n",
            "  –æ–±—Ä–∞–∑/NOUN\n",
            "  –π–¥–µ/VERB\n",
            "  –Ω–∞/ADP\n",
            "  100/NUM\n",
            "  –≤—ñ–¥—Å–æ—Ç–∫—ñ–≤/NOUN\n",
            "  ,/PUNCT\n",
            "  —Ç–æ/PART\n",
            "  —ñ–Ω—à–∏–π/DET\n",
            "  –≤/ADP\n",
            "  –Ω—å–æ–º—É/PRON\n",
            "  –º–æ–∂–µ/VERB\n",
            "  –ø–æ–±–∞—á–∏—Ç–∏/VERB\n",
            "  —Å–µ–±–µ/PRON\n",
            "  –Ω–µ/PART\n",
            "  –∫—Ä–∞—Å–∏–≤–∏–º/ADJ\n",
            "  ./PUNCT\n",
            "  —à—É–∫–∞—î–º–æ/SYM\n",
            "  —Ç–æ/DET\n",
            "  —â–æ/PRON\n",
            "  –π–¥–µ/VERB\n",
            "  —Ç—ñ–ª—å–∫–∏/PART\n",
            "  –≤–∞–º/PRON\n",
            "  !/PUNCT\n",
            "  üì∏–æ–±—Ä–∞–∑/X\n",
            "  –Ω–µ/PART\n",
            "  –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î/VERB\n",
            "  —Å—Ç–æ—Ä–æ–Ω–∏/NOUN\n",
            "  !/PUNCT\n",
            "  —á–∞—Å—Ç–æ/ADV\n",
            "  –≤–∏/PRON\n",
            "  –Ω–µ/PART\n",
            "  –ø–æ–¥–æ–±–∞—î—Ç–µ—Å—è/VERB\n",
            "  —Å–æ–±—ñ/PRON\n",
            "  –Ω–∞/ADP\n",
            "  —Ñ–æ—Ç–æ/NOUN\n",
            "  –Ω–µ/PART\n",
            "  —Ç–æ–º—É/ADV\n",
            "  —â–æ/PRON\n",
            "  –≤–∏/PRON\n",
            "  –ø–æ–≥–∞–Ω–æ/ADV\n",
            "  –≤–∏–π—à–ª–∏/VERB\n",
            "  –≤/ADP\n",
            "  –∫–∞–¥—Ä—ñ/NOUN\n",
            "  ,/PUNCT\n",
            "  –∞/CCONJ\n",
            "  —Ç–æ–º—É/ADV\n",
            "  —â–æ/PRON\n",
            "  –ø—Ä–æ—Å—Ç–æ/PART\n",
            "  –≤–∞—à/DET\n",
            "  –æ–¥—è–≥/NOUN\n",
            "  –∞–±—Å–æ–ª—é—Ç–Ω–æ/ADV\n",
            "  –Ω–µ/PART\n",
            "  –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î/VERB\n",
            "  —Å—Ç–∏–ª—é/NOUN\n",
            "  –æ–±—Ä–∞–Ω–æ—ó/NOUN\n",
            "  –ª–æ–∫–∞—Ü—ñ—ó/NOUN\n",
            "  ./PUNCT\n",
            "  –∑–∞–≤–∂–¥–∏/ADV\n",
            "  –æ–±–≥–æ–≤–æ—Ä—é–π—Ç–µ/NOUN\n",
            "  —Ü–µ–π/PRON\n",
            "  –º–æ–º–µ–Ω—Ç/NOUN\n",
            "  –∑/ADP\n",
            "  —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–æ–º/NOUN\n",
            "  ,/PUNCT\n",
            "  –≤–æ–Ω–∞/PRON\n",
            "  //PROPN\n",
            "  –≤—ñ–Ω/PRON\n",
            "  –∑–∞–≤–∂–¥–∏/ADV\n",
            "  –∑/ADP\n",
            "  —Ä–∞–¥—ñ—Å—Ç—é/NOUN\n",
            "  –≤–∞–º/PRON\n",
            "  —â–æ—Å—å/SCONJ\n",
            "  –ø—ñ–¥–∫–∞–∂–µ/VERB\n",
            "  —ñ/CCONJ\n",
            "  –ø—ñ–¥–±–µ—Ä–µ/VERB\n",
            "  –æ–¥—è–≥/VERB\n",
            "  –¥–æ/ADP\n",
            "  —Ñ–æ—Ç–æ—Å—Ç—É–¥—ñ—ó/NOUN\n",
            "  ./PUNCT\n",
            "  —Ä–µ—Ç–µ–ª—å–Ω–æ/SYM\n",
            "  –ø—ñ–¥–±–∏—Ä–∞–π—Ç–µ/NOUN\n",
            "  –æ–±—Ä–∞–∑–∏/NOUN\n",
            "  –Ω–∞/ADP\n",
            "  —Ñ–æ—Ç–æ—Å–µ—Å—ñ—é/NOUN\n",
            "  ,/PUNCT\n",
            "  –º–∞–∫—ñ—è–∂/NOUN\n",
            "  —ñ/CCONJ\n",
            "  –∑–∞—á—ñ—Å–∫—É/NOUN\n",
            "  !/PUNCT)\n"
          ]
        }
      ]
    }
  ]
}